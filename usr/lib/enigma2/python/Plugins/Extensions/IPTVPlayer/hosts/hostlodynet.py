# -*- coding: utf8 -*-
from Plugins.Extensions.IPTVPlayer.tools.iptvtools import printDBG, printExc, byteify
from Plugins.Extensions.IPTVPlayer.components.ihost import CHostBase, CBaseHostClass
from Plugins.Extensions.IPTVPlayer.tools.iptvtypes import strwithmeta
from Plugins.Extensions.IPTVPlayer.libs.jsunpack import unpack, detect, get_packed_data
from Plugins.Extensions.IPTVPlayer.libs import ph
import base64, urllib, re, time, os, requests, hashlib, subprocess, threading, json, sys
try:
    from urllib.parse import quote_plus, urljoin, quote  # Python 3
except ImportError:
    from urllib import quote_plus  # Python 2
    from urlparse import urljoin
#################################################
def GetCookieDir(cookieFileName=''):
    try:
        COOKIE_PATH = '/tmp/IPTV_Cookies'
        if not os.path.exists(COOKIE_PATH):
            os.makedirs(COOKIE_PATH)
        if cookieFileName:
            return os.path.join(COOKIE_PATH, cookieFileName)
        return COOKIE_PATH
    except Exception as e:
        print('GetCookieDir Error:', e)
        return '/tmp'
def getDirectM3U8Playlist(m3u8Url, checkContent=False):
    import requests
    results = []
    try:
        printDBG('getDirectM3U8Playlist >>> ' + m3u8Url)
        headers = {'User-Agent': 'Mozilla/5.0', 'Referer': m3u8Url}
        data = requests.get(m3u8Url, headers=headers, timeout=10).text
        matches = re.findall(r'#EXT-X-STREAM-INF:[^\n]*RESOLUTION=(\d+x\d+)[^\n]*\n([^\n]+)', data)
        if matches:
            for res, link in matches:
                quality = res.split('x')[-1] + 'p'
                if not link.startswith('http'):
                    base = m3u8Url[:m3u8Url.rfind('/')+1]
                    link = base + link
                results.append({'name': quality, 'url': link})
        else:
            results.append({'name': 'direct', 'url': m3u8Url})
    except Exception as e:
        printDBG('getDirectM3U8Playlist error: %s' % e)
        results = [{'name': 'direct', 'url': m3u8Url}]
    return results
def printDBG(txt):
    try:
        print(txt)
    except:
        pass
def getinfo():
    info_ = {}
    name = 'Lodynet'
    hst = 'https://lodynet.watch'
    info_['host'] = hst
    info_['name'] = name
    info_['version'] = '5.0 26/10/2025'
    info_['dev'] = 'RGYSoft + Angel_heart'
    info_['desc'] = 'Ø§ÙÙ„Ø§Ù… Ùˆ Ù…Ø³Ù„Ø³Ù„Ø§Øª ÙˆØ¨Ø±Ø§Ù…Ø¬ ÙˆØ­ÙÙ„Ø§Øª ÙˆÙƒØ±ØªÙˆÙ† ÙˆØ£ØºØ§Ù†ÙŠ ÙˆÙ…Ù…Ø«Ù„ÙŠÙ†'
    info_['icon'] = 'https://www.lodynet.co/wp-content/uploads/2015/12/logo-1.png'
    return info_
class Lodynet(CBaseHostClass):
    def __init__(self):
        params = {'history': 'lodynet.history','cookie': 'lodynet.cookie','history_store_type': False}
        CBaseHostClass.__init__(self, params)
        self.MAIN_URL = getinfo()['host']
        self.DEFAULT_ICON_URL = getinfo()['icon']
        self.USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    def searchItems(self):
        if self._historyLenTextFunction:
            return [
                {'category': 'search', 'title': 'Ø¨Ø­Ø«', 'search_item': True, },
                {'category': 'search_history', 'title': 'Ø³Ø¬Ù„ Ø§Ù„Ø¨Ø­Ø«', 'desc': 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†Ù‡Ø§.'},
                {'category': 'delete_history', 'title': 'Ø­Ø°Ù Ø³Ø¬Ù„ Ø§Ù„Ø¨Ø­Ø«', 'desc': self._historyLenTextFunction}
            ]
        else:
            return []
    def getPage(self, url, params={}, post_data=None):
        HTTP_HEADER = {'User-Agent': self.USER_AGENT,'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8','Accept-Language': 'ar,en-US;q=0.7,en;q=0.3','Accept-Encoding': 'gzip, deflate','Referer': self.MAIN_URL}
        params.update({'header': HTTP_HEADER})
        url = self.encodeUrl(url)
        return self.cm.getPage(url, params, post_data)
    def getFullUrl(self, url):
        if not url:
            return self.DEFAULT_ICON_URL
        if url.startswith('//'):
            url = 'https:' + url
        elif url.startswith('/'):
            url = self.MAIN_URL + url
        elif not url.startswith('http'):
            url = self.MAIN_URL + '/' + url
        if any(ext in url.lower() for ext in ['.jpg', '.jpeg', '.png', '.webp', '.gif']):
            if not url.startswith('http'):
                return self.DEFAULT_ICON_URL
        url = self.encodeUrl(url)
        return url
    def cleanHtmlStr(self, data):
        data = data.replace('&nbsp;', ' ')
        data = data.replace('&quot;', '"')
        data = re.sub(r'\s+', ' ', data)
        return data.strip()
    def encodeUrl(self, url):
        try:
            if isinstance(url, str):
                parts = re.match(r'^(https?://)(.*)$', url)
                if parts:
                    base, rest = parts.groups()
                    rest_encoded = quote(rest, safe="/:%#?=&")
                    return base + rest_encoded
            return url
        except Exception as e:
            printExc()
            return url
    def listsTab(self, tab, cItem):
        for item in tab:
            params = dict(cItem)
            params.update(item)
            self.addDir(params)
    def listMainMenu(self, cItem):
        printDBG('Lodynet.listMainMenu')
        MAIN_CAT_TAB = [
            {'category': 'sub_menu', 'title': 'Ù…Ø³Ù„Ø³Ù„Ø§Øª', 'mode': '10', 'sub_mode': 0},
            {'category': 'sub_menu', 'title': 'Ø£ÙÙ„Ø§Ù…', 'mode': '10', 'sub_mode': 1},
            {'category': 'list_items', 'title': 'Ø¨Ø±Ø§Ù…Ø¬ Ùˆ Ø­ÙÙ„Ø§Øª', 'url': '/category/Ø§Ù„Ø¨Ø±Ø§Ù…Ø¬-Ùˆ-Ø­ÙÙ„Ø§Øª-tv/'},
            {'category': 'sub_menu', 'title': 'Ø£ØºØ§Ù†ÙŠ', 'mode': '10', 'sub_mode': 2},
            {'category': 'list_items', 'title': 'Ø§Ù„Ù…Ø¶Ø§Ù Ø­Ø¯ÙŠØ«Ø§Ù‹', 'url': '/', 'sub_mode': 'newly'},
        ]
        self.listsTab(MAIN_CAT_TAB, cItem)
        search_items = self.searchItems()
        for item in search_items:
            params = dict(cItem)
            params.update(item)
            self.addDir(params)
    def listSubMenu(self, cItem):
        printDBG('Lodynet.listSubMenu')
        gnr = cItem.get('sub_mode', '')
        if gnr == 0: 
            SUB_CAT_TAB = [
                {'category': 'list_items', 'title': 'Ù…Ø³Ù„Ø³Ù„Ø§Øª Ù‡Ù†Ø¯ÙŠØ©', 'url': '/category/Ù…Ø³Ù„Ø³Ù„Ø§Øª-Ù‡Ù†Ø¯ÙŠØ©-Ù…ØªØ±Ø¬Ù…Ø©/'},
                {'category': 'list_items', 'title': 'Ù…Ø³Ù„Ø³Ù„Ø§Øª Ù‡Ù†Ø¯ÙŠØ© Ù…Ø¯Ø¨Ù„Ø¬Ø©', 'url': '/dubbed-indian-series-p5/'},
                {'category': 'list_items', 'title': 'Ù…Ø³Ù„Ø³Ù„Ø§Øª ÙˆÙŠØ¨ Ù‡Ù†Ø¯ÙŠØ©', 'url': '/category/Ù…Ø³Ù„Ø³Ù„-ÙˆÙŠØ¨-Ù‡Ù†Ø¯ÙŠØ©/'},
                {'category': 'list_items', 'title': 'Ù…Ø³Ù„Ø³Ù„Ø§Øª Ù‡Ù†Ø¯ÙŠØ© 2020', 'url': '/release-year/Ù…Ø³Ù„Ø³Ù„Ø§Øª-Ù‡Ù†Ø¯ÙŠØ©-2020-a/'},
                {'category': 'list_items', 'title': 'Ù…Ø³Ù„Ø³Ù„Ø§Øª Ù‡Ù†Ø¯ÙŠØ© 2019', 'url': '/release-year/Ù…Ø³Ù„Ø³Ù„Ø§Øª-Ù‡Ù†Ø¯ÙŠØ©-2019/'},
                {'category': 'list_items', 'title': 'Ù…Ø³Ù„Ø³Ù„Ø§Øª Ù‡Ù†Ø¯ÙŠØ© 2018', 'url': '/release-year/Ù…Ø³Ù„Ø³Ù„Ø§Øª-Ù‡Ù†Ø¯ÙŠØ©-2018/'},
                {'category': 'list_items', 'title': 'Ù…Ø³Ù„Ø³Ù„Ø§Øª ØªØ±ÙƒÙŠØ©', 'url': '/category/Ù…Ø³Ù„Ø³Ù„Ø§Øª-ØªØ±ÙƒÙŠ/'},
                {'category': 'list_items', 'title': 'Ù…Ø³Ù„Ø³Ù„Ø§Øª ØªØ±ÙƒÙŠØ© Ù…Ø¯Ø¨Ù„Ø¬Ø©', 'url': '/dubbed-turkish-series-g/'},
                {'category': 'list_items', 'title': 'Ù…Ø³Ù„Ø³Ù„Ø§Øª ÙƒÙˆØ±ÙŠØ©', 'url': '/korean-series-b/'},
                {'category': 'list_items', 'title': 'Ù…Ø³Ù„Ø³Ù„Ø§Øª ØµÙŠÙ†ÙŠØ©', 'url': '/category/Ù…Ø³Ù„Ø³Ù„Ø§Øª-ØµÙŠÙ†ÙŠØ©-Ù…ØªØ±Ø¬Ù…Ø©/'},
                {'category': 'list_items', 'title': 'Ù…Ø³Ù„Ø³Ù„Ø§Øª ØªØ§ÙŠÙ„Ø§Ù†Ø¯ÙŠØ©', 'url': '/Ù…Ø´Ø§Ù‡Ø¯Ø©-Ù…Ø³Ù„Ø³Ù„Ø§Øª-ØªØ§ÙŠÙ„Ù†Ø¯ÙŠØ©/'},
                {'category': 'list_items', 'title': 'Ù…Ø³Ù„Ø³Ù„Ø§Øª Ø¨Ø§ÙƒØ³ØªØ§Ù†ÙŠØ©', 'url': '/category/Ø§Ù„Ù…Ø³Ù„Ø³Ù„Ø§Øª-Ø¨Ø§ÙƒØ³ØªØ§Ù†ÙŠØ©/'},
                {'category': 'list_items', 'title': 'Ù…Ø³Ù„Ø³Ù„Ø§Øª Ø¢Ø³ÙŠÙˆÙŠØ© Ø­Ø¯ÙŠØ«Ø©', 'url': '/tag/new-asia/'},
                {'category': 'list_items', 'title': 'Ù…Ø³Ù„Ø³Ù„Ø§Øª Ù…ÙƒØ³ÙŠÙƒÙŠØ©', 'url': '/category/Ù…Ø³Ù„Ø³Ù„Ø§Øª-Ù…ÙƒØ³ÙŠÙƒÙŠØ©-a/'},
                {'category': 'list_items', 'title': 'Ù…Ø³Ù„Ø³Ù„Ø§Øª Ø£Ø¬Ù†Ø¨ÙŠØ©', 'url': '/category/Ù…Ø³Ù„Ø³Ù„Ø§Øª-Ø§Ø¬Ù†Ø¨ÙŠØ©/'},
            ]
        elif gnr == 1:
            SUB_CAT_TAB = [
                {'category': 'list_items', 'title': 'Ø§ÙÙ„Ø§Ù… Ù‡Ù†Ø¯ÙŠØ©', 'url': '/category/Ø§ÙÙ„Ø§Ù…-Ù‡Ù†Ø¯ÙŠØ©/'},
                {'category': 'list_items', 'title': 'Ø£ÙÙ„Ø§Ù… Ù‡Ù†Ø¯ÙŠØ© Ù…Ø¯Ø¨Ù„Ø¬Ø©', 'url': '/category/Ø£ÙÙ„Ø§Ù…-Ù‡Ù†Ø¯ÙŠØ©-Ù…Ø¯Ø¨Ù„Ø¬Ø©/'},
                {'category': 'list_items', 'title': 'Ø§ÙÙ„Ø§Ù… Ù‡Ù†Ø¯ÙŠØ© Ø¬Ù†ÙˆØ¨ÙŠØ©', 'url': '/tag/Ø§Ù„Ø§ÙÙ„Ø§Ù…-Ø§Ù„Ù‡Ù†Ø¯ÙŠØ©-Ø§Ù„Ø¬Ù†ÙˆØ¨ÙŠØ©/'},
                {'category': 'list_items', 'title': 'Ø£ÙÙ„Ø§Ù… Ù‡Ù†Ø¯ÙŠ 2025', 'url': '/release-year/Ø£ÙÙ„Ø§Ù…-Ù‡Ù†Ø¯ÙŠ-2025/'},
                {'category': 'list_items', 'title': 'Ø£ÙÙ„Ø§Ù… Ù‡Ù†Ø¯ÙŠ 2024', 'url': '/release-year/Ø£ÙÙ„Ø§Ù…-Ù‡Ù†Ø¯ÙŠ-2024/'},
                {'category': 'list_items', 'title': 'Ø£ÙÙ„Ø§Ù… Ù‡Ù†Ø¯ÙŠ 2023', 'url': '/release-year/Ø£ÙÙ„Ø§Ù…-Ù‡Ù†Ø¯ÙŠØ©-2023/'},
                {'category': 'list_items', 'title': 'Ø£ÙÙ„Ø§Ù… Ù‡Ù†Ø¯ÙŠ 2021', 'url': '/release-year/movies-hindi-2021/'},
                {'category': 'list_items', 'title': 'Ø£ÙÙ„Ø§Ù… Ù‡Ù†Ø¯ÙŠ 2020', 'url': '/release-year/Ø§ÙÙ„Ø§Ù…-Ù‡Ù†Ø¯ÙŠ-2020-a/'},
                {'category': 'list_items', 'title': 'Ø§ÙÙ„Ø§Ù… Ù‡Ù†Ø¯ÙŠ 2019', 'url': '/release-year/Ø§ÙÙ„Ø§Ù…-Ù‡Ù†Ø¯ÙŠ-2019/'},
                {'category': 'list_items', 'title': 'Ø§ÙÙ„Ø§Ù… Ù‡Ù†Ø¯ÙŠ 2018', 'url': '/release-year/Ø§ÙÙ„Ø§Ù…-Ù‡Ù†Ø¯ÙŠ-2018/'},
                {'category': 'list_items', 'title': 'Ø§ÙÙ„Ø§Ù… Ù‡Ù†Ø¯ÙŠ 2017', 'url': '/release-year/Ø§ÙÙ„Ø§Ù…-Ù‡Ù†Ø¯ÙŠ-2017/'},
                {'category': 'list_items', 'title': 'Ø§ÙÙ„Ø§Ù… Ù‡Ù†Ø¯ÙŠ 2016', 'url': '/release-year/2016/'},
                {'category': 'list_items', 'title': 'Ø§ÙÙ„Ø§Ù… Ù‡Ù†Ø¯ÙŠØ© 4K', 'url': '/tag/Ø§ÙÙ„Ø§Ù…-Ù‡Ù†Ø¯ÙŠØ©-Ù…ØªØ±Ø¬Ù…Ø©-Ø¨Ø¬ÙˆØ¯Ø©-4k/'},
                {'category': 'list_items', 'title': 'Ø£Ù…ÙŠØªØ§Ø¨ Ø¨Ø§ØªØ´Ø§Ù†', 'url': '/actor/Ø£Ù…ÙŠØªØ§Ø¨-Ø¨Ø§ØªØ´Ø§Ù†/'},
                {'category': 'list_items', 'title': 'Ø§Ø¹Ù…Ø§Ù„ Ø´Ø§Ø±ÙˆØ®Ø§Ù†', 'url': '/actor/Ø´Ø§Ù‡-Ø±ÙˆØ®-Ø®Ø§Ù†-a/'},
                {'category': 'list_items', 'title': 'Ø£Ø¹Ù…Ø§Ù„ Ø³Ù„Ù…Ø§Ù† Ø®Ø§Ù†', 'url': '/actor/Ø³Ù„Ù…Ø§Ù†-Ø®Ø§Ù†-a/'},
                {'category': 'list_items', 'title': 'Ø£Ø¹Ù…Ø§Ù„ Ø¹Ø§Ù…Ø± Ø®Ø§Ù†', 'url': '/actor/Ø¹Ø§Ù…Ø±-Ø®Ø§Ù†-a/'},
                {'category': 'list_items', 'title': 'Ø£Ø¹Ù…Ø§Ù„ Ø´Ø§Ù‡Ø¯ ÙƒØ§Ø¨ÙˆØ±', 'url': '/actor/Ø´Ø§Ù‡ÙŠØ¯-ÙƒØ§Ø¨ÙˆØ±/'},
                {'category': 'list_items', 'title': 'Ø£Ø¹Ù…Ø§Ù„ Ø±Ø§Ù†Ø¨ÙŠØ± ÙƒØ§Ø¨ÙˆØ±', 'url': '/actor/Ø±Ø§Ù†Ø¨ÙŠØ±-ÙƒØ§Ø¨ÙˆØ±/'},
                {'category': 'list_items', 'title': 'Ø£Ø¹Ù…Ø§Ù„ Ø¯ÙŠØ¨ÙŠÙƒØ§ Ø¨Ø§Ø¯ÙƒÙˆÙ†', 'url': '/actor/Ø¯ÙŠØ¨ÙŠÙƒØ§-Ø¨Ø§Ø¯ÙƒÙˆÙ†/'},
                {'category': 'list_items', 'title': 'Ø£Ø¹Ù…Ø§Ù„ Ø¬ÙŠÙ†ÙŠÙØ± ÙˆÙ†Ø¬Øª', 'url': '/actor/Ø¬ÙŠÙ†ÙŠÙØ±-ÙˆÙ†Ø¬Øª/'},
                {'category': 'list_items', 'title': 'Ø£Ø¹Ù…Ø§Ù„ Ù‡Ø±ÙŠØªÙŠÙƒ Ø±ÙˆØ´Ø§Ù†', 'url': '/actor/Ù‡Ø±ÙŠØªÙŠÙƒ-Ø±ÙˆØ´Ø§Ù†/'},
                {'category': 'list_items', 'title': 'Ø£Ø¹Ù…Ø§Ù„ Ø§ÙƒØ´Ø§ÙŠ ÙƒÙˆÙ…Ø§Ø±', 'url': '/actor/Ø§ÙƒØ´Ø§ÙŠ-ÙƒÙˆÙ…Ø§Ø±/'},
                {'category': 'list_items', 'title': 'Ø£Ø¹Ù…Ø§Ù„ ØªØ§Ø¨Ø³ÙŠ Ø¨Ø§Ù†Ùˆ', 'url': '/actor/ØªØ§Ø¨Ø³ÙŠ-Ø¨Ø§Ù†Ùˆ/'},
                {'category': 'list_items', 'title': 'Ø£Ø¹Ù…Ø§Ù„ Ø³Ø§Ù†Ø¬Ø§ÙŠ Ø¯ÙˆØª', 'url': '/actor/Ø³Ø§Ù†Ø¬Ø§ÙŠ-Ø¯ÙˆØª-a/'},
                {'category': 'list_items', 'title': 'ØªØ±Ø¬Ù…Ø§Øª Ø§Ø­Ù…Ø¯ Ø¨Ø´ÙŠØ±', 'url': '/tag/Ø¬Ù…ÙŠØ¹-Ø§Ù„Ø£ÙÙ„Ø§Ù…-ÙÙŠ-Ù‡Ø°Ø§-Ø§Ù„Ù‚Ø³Ù…-Ù…Ù†-ØªØ±Ø¬Ù…Ø©-Ø£Ø­Ù…Ø¯/'},
                {'category': 'list_items', 'title': 'Ø§ÙÙ„Ø§Ù… ØªØ±ÙƒÙŠØ© Ù…ØªØ±Ø¬Ù…', 'url': '/category/Ø§ÙÙ„Ø§Ù…-ØªØ±ÙƒÙŠØ©-Ù…ØªØ±Ø¬Ù…/'},
                {'category': 'list_items', 'title': 'Ø§ÙÙ„Ø§Ù… Ø¨Ø§ÙƒØ³ØªØ§Ù†ÙŠØ©', 'url': '/tag/Ø§ÙÙ„Ø§Ù…-Ø¨Ø§ÙƒØ³ØªØ§Ù†ÙŠØ©-Ù…ØªØ±Ø¬Ù…Ø©/'},
                {'category': 'list_items', 'title': 'Ø§ÙÙ„Ø§Ù… Ø§Ø³ÙŠÙˆÙŠØ©', 'url': '/category/Ø§ÙÙ„Ø§Ù…-Ø§Ø³ÙŠÙˆÙŠØ©-a/'},
                {'category': 'list_items', 'title': 'Ø§ÙÙ„Ø§Ù… Ø§Ø¬Ù†Ø¨ÙŠ', 'url': '/category/Ø§ÙÙ„Ø§Ù…-Ø§Ø¬Ù†Ø¨ÙŠØ©-Ù…ØªØ±Ø¬Ù…Ø©-a/'},
                {'category': 'list_items', 'title': 'Ø§Ù†ÙŠÙ…ÙŠ', 'url': '/category/Ø§Ù†ÙŠÙ…ÙŠ/'},
            ]
        elif gnr == 2:
            SUB_CAT_TAB = [
                {'category': 'list_items', 'title': 'Ø£ØºØ§Ù†ÙŠ Ø§Ù„Ù…Ø³Ù„Ø³Ù„Ø§Øª', 'url': '/category/Ø§ØºØ§Ù†ÙŠ/Ø§ØºØ§Ù†ÙŠ-Ø§Ù„Ù…Ø³Ù„Ø³Ù„Ø§Øª-Ø§Ù„Ù‡Ù†Ø¯ÙŠØ©/'},
                {'category': 'list_items', 'title': 'ØªØµØ§Ù…ÙŠÙ… Ù…Ø³Ù„Ø³Ù„Ø§Øª Ù‡Ù†Ø¯ÙŠØ©', 'url': '/category/ØªØµØ§Ù…ÙŠÙ…-Ù…Ø³Ù„Ø³Ù„Ø§Øª-Ø§Ù„Ù‡Ù†Ø¯ÙŠØ©/'},
                {'category': 'list_items', 'title': 'Ø£ØºØ§Ù†ÙŠ Ø§Ù„Ø£ÙÙ„Ø§Ù…', 'url': '/category/Ø§ØºØ§Ù†ÙŠ-Ø§Ù„Ø§ÙÙ„Ø§Ù…/'},
                {'category': 'list_items', 'title': 'Ø§ØºØ§Ù†ÙŠ Ù‡Ù†Ø¯ÙŠØ© mp3', 'url': '/category/Ø§ØºØ§Ù†ÙŠ/Ø§ØºØ§Ù†ÙŠ-Ù‡Ù†Ø¯ÙŠØ©-mp3/'},
            ]
        self.listsTab(SUB_CAT_TAB, cItem)
    def listItems(self, cItem):
        printDBG("Lodynet.listItems [%s]" % cItem)
        url = cItem.get('url', '')
        page = cItem.get('page', 1)
        sub_mode = cItem.get('sub_mode', '')
        if not url.startswith('http'):
            url = self.getFullUrl(url)
        if page > 1:
            if '/page/' in url:
                url = re.sub(r'/page/\d+', '/page/' + str(page), url)
            else:
                url = url.rstrip('/') + '/page/' + str(page)
        sts, data = self.getPage(url)
        if not sts:
            return
        items = re.findall(r'<div class="ItemNewly">(.*?)</div>\s*</a>\s*</div>', data, re.S)
        items_added = 0
        for item in items:
            title_match = re.search(r'title="([^"]+)"', item)
            url_match = re.search(r'href="([^"]+)"', item)
            img_match = re.search(r'data-src="([^"]+)"', item)
            if not all([title_match, url_match, img_match]):
                continue
            title = title_match.group(1)
            item_url = url_match.group(1)
            img = img_match.group(1)
            item_url = self.getFullUrl(item_url)
            img = self.getFullUrl(img)
            desc = self.extractDescFromNewly(item)
            content_type = self.determineContentType(title, item_url)
            if content_type == 'series':
                params = {'category': 'list_episodes','title': title.strip(),'url': item_url,'desc': desc,'icon': img,'good_for_fav': True}
                self.addDir(params)
            else:
                params = {'category': 'video','title': title.strip(),'url': item_url,'desc': desc,'icon': img,'good_for_fav': True}
                self.addVideo(params)
            items_added += 1
        if sub_mode == 'newly' and items_added > 0:
            is_newly_section = (url == self.MAIN_URL + '/' or 
                               url.startswith(self.MAIN_URL + '/page/'))
            if is_newly_section:
                next_page = page + 1
                next_url = self.MAIN_URL + '/page/' + str(next_page) + '/'
                self.addDir({'category': 'list_items', 'title': '\\c00????00 Ø§Ù„ØµÙØ­Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© (' + str(next_page) + ')','url': next_url,'icon': '','desc': '\\c00????00 Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ø§Ù„ØµÙØ­Ø© ' + str(next_page),'page': next_page,'sub_mode': 'newly'})
        more_match = False
        pick_up_order = ''
        pick_up_id = ''
        more_match1 = re.search(r'onclick="[^"]*GetMoreCategory\(\'([^\']+)\',\s*\'([^\']+)\'\)"', data)
        if more_match1:
            pick_up_order = more_match1.group(1)
            pick_up_id = more_match1.group(2)
            more_match = True
            printDBG("ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø²Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø²ÙŠØ¯ - Ø§Ù„Ù†Ù…Ø· 1: order=%s, id=%s" % (pick_up_order, pick_up_id))
        if not more_match:
            more_match2 = re.search(r'onclick="[^"]*GetMoreCategory\(\'([^\']+)\',\s*\'([^\']+)\'\)[^"]*"', data)
            if more_match2:
                pick_up_order = more_match2.group(1)
                pick_up_id = more_match2.group(2)
                more_match = True
                printDBG("ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø²Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø²ÙŠØ¯ - Ø§Ù„Ù†Ù…Ø· 2: order=%s, id=%s" % (pick_up_order, pick_up_id))
        if more_match and pick_up_order and pick_up_id:
            parent_id = ''
            parent_match1 = re.search(r"DataPosting\.append\('parent',\s*'(\d+)'\)", data)
            if parent_match1:
                parent_id = parent_match1.group(1)
                printDBG("ØªÙ… Ø§ÙƒØªØ´Ø§Ù parent_id - Ø§Ù„Ù†Ù…Ø· 1: %s" % parent_id)
            if not parent_id:
                parent_match2 = re.search(r"append\('parent',\s*'(\d+)'\)", data)
                if parent_match2:
                    parent_id = parent_match2.group(1)
                    printDBG("ØªÙ… Ø§ÙƒØªØ´Ø§Ù parent_id - Ø§Ù„Ù†Ù…Ø· 2: %s" % parent_id)
            type_match = re.search(r"DataPosting\.append\('type',\s*'([^']+)'\)", data)
            taxonomy_match = re.search(r"DataPosting\.append\('taxonomy',\s*'([^']+)'\)", data)
            data_type = type_match.group(1) if type_match else 'Category'
            taxonomy = taxonomy_match.group(1) if taxonomy_match else 'category'
            if parent_id:
                params = dict(cItem)
                params.update({'category': 'load_more','title': '\\c00????00 ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø²ÙŠØ¯','pick_up_order': pick_up_order,'pick_up_id': pick_up_id,'parent_id': parent_id,'data_type': data_type,'taxonomy': taxonomy})
                self.addDir(params)
                printDBG("ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø²Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø²ÙŠØ¯: order=%s, id=%s, parent=%s" % (pick_up_order, pick_up_id, parent_id))
            else:
                printDBG("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ parent_idØŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ø²Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø²ÙŠØ¯")
        else:
            printDBG("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø²Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø²ÙŠØ¯ ÙÙŠ Ø§Ù„ØµÙØ­Ø©")
            if sub_mode != 'newly':
                next_match = re.search(r'class="next page-numbers".*?href="([^"]+)"', data)
                if next_match:
                    next_url = self.getFullUrl(next_match.group(1))
                    params = dict(cItem)
                    params.update({'category': 'list_items','title': '\\c00????00 Ø§Ù„ØµÙØ­Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©', 'url': cItem['url'],'page': page + 1})
                    self.addDir(params)
    def listEpisodes(self, cItem):
        printDBG("Lodynet.listEpisodes [%s]" % cItem)
        url = cItem.get('url', '')
        if not url.startswith('http'):
            url = self.getFullUrl(url)
        sts, data = self.getPage(url)
        if not sts:
            self.addDir({'category': 'list_episodes', 'title': '\\c00????20Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø©','url': '','icon': '','desc': 'ØªØ¹Ø°Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø©ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹'})
            return
        items_added = 0
        item_blocks = re.findall(r'(<div class="ItemNewly">.*?</div>\s*</a>\s*</div>)', data, re.S)
        if item_blocks:
            for item_block in item_blocks:
                title_match = re.search(r'<a title="([^"]+)"', item_block)
                url_match = re.search(r'href="([^"]+)"', item_block)
                img_match = re.search(r'data-src="([^"]+)"', item_block)
                if not all([title_match, url_match, img_match]):
                    continue
                title = title_match.group(1)
                item_url = url_match.group(1)
                img = img_match.group(1)
                if any(x in str(value) for value in [title, item_url, img] for x in ["+ CategoryItem.", "CategoryItem."]):
                    printDBG("ØªØ®Ø·ÙŠ Ø¹Ù†ØµØ± ØºÙŠØ± ØµØ§Ù„Ø­ ÙÙŠ Ø§Ù„Ø­Ù„Ù‚Ø§Øª: " + title)
                    continue
                icon = self.getFullUrl(img)
                desc = self.extractDescFromNewly(item_block)
                self.addVideo({'category': 'video','title': title.strip(),'url': item_url,'desc': desc,'icon': icon,'good_for_fav': True})
                items_added += 1
        if items_added == 0:
            self.addDir({'category': 'list_episodes','title': '\\c00????20Ù„Ø§ ØªÙˆØ¬Ø¯ Ø­Ù„Ù‚Ø§Øª Ù…ØªØ§Ø­Ø©','url': '','icon': '','desc': 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ø­Ù„Ù‚Ø§Øª Ù…ØªØ§Ø­Ø© Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³Ù„Ø³Ù„ Ø­Ø§Ù„ÙŠØ§Ù‹.\nÙ‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„Ø³Ø¨Ø¨:\n- Ø§Ù„Ø­Ù„Ù‚Ø§Øª ØºÙŠØ± Ù…ØªÙˆÙØ±Ø© Ø¨Ø¹Ø¯\n- Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ù…Ø¤Ù‚ØªØ© Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹\n- Ø§Ù„Ù…Ø³Ù„Ø³Ù„ Ù‚Ø¯ÙŠÙ… ÙˆÙ„Ù… ÙŠØ¹Ø¯ Ù…ØªØ§Ø­Ø§Ù‹'})
        more_match = re.search(r'<span id="ItemMoreBtn"[^>]*onclick="[^"]*GetMoreCategory\(\'([^\']+)\',\s*\'([^\']+)\'\)"', data)
        if more_match:
            pick_up_order = more_match.group(1)
            pick_up_id = more_match.group(2)
            parent_match = re.search(r"DataPosting\.append\('parent',\s*'(\d+)'\)", data)
            parent_id = parent_match.group(1) if parent_match else ''
            if pick_up_id and parent_id:
                self.addDir({'category': 'load_more_episodes','title': '\\c00FFFF00 ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø­Ù„Ù‚Ø§Øª','url': url,'icon': '','desc': '','pick_up_order': pick_up_order,'pick_up_id': pick_up_id,'parent_id': parent_id,'data_type': 'Category','taxonomy': 'category','is_episodes': True})
        else:
            next_match = re.search(r'class="nextpage-numbers".*?href="([^"]+)"', data)
            if next_match:
                next_url = self.getFullUrl(next_match.group(1))
                self.addDir({'category': 'list_episodes','title': '\\c00FFFF00Ø§Ù„ØµÙØ­Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„Ù„Ø­Ù„Ù‚Ø§Øª','url': next_url,'desc': '','icon': ''})
    def loadMore(self, cItem):
        printDBG("Lodynet.loadMore [%s]" % cItem)
        pick_up_order = cItem.get('pick_up_order', 'category')
        pick_up_id = cItem.get('pick_up_id')
        parent_id = cItem.get('parent_id')
        data_type = cItem.get('data_type', 'Category')
        taxonomy = cItem.get('taxonomy', 'category')
        is_episodes = cItem.get('is_episodes', False)
        if not pick_up_id or not parent_id:
            self.addDir({'category': 'list_items', 'title': 'Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø²ÙŠØ¯', 'url': ''})
            return
        API_URL = self.MAIN_URL + "/wp-content/themes/Lodynet2020/Api/RequestMoreCategory.php"
        try:
            post_data = {"order": pick_up_order,"parent": parent_id, "type": data_type,"taxonomy": taxonomy,"id": pick_up_id}
            printDBG("Load More POST data: %s" % post_data)
            headers = {"User-Agent": self.USER_AGENT,"X-Requested-With": "XMLHttpRequest","Content-Type": "application/x-www-form-urlencoded; charset=UTF-8","Referer": self.MAIN_URL}
            import requests
            response = requests.post(API_URL, data=post_data, headers=headers, timeout=30)
            response_text = response.text
            if response_text and response_text.strip():
                try:
                    items = json.loads(response_text)
                    if isinstance(items, list) and items:
                        printDBG("ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… %d Ø¹Ù†ØµØ± Ù…Ù† API" % len(items))
                        valid_items = []
                        for item in items:
                            if not isinstance(item, dict):
                                continue
                            title = item.get("name", "")
                            url = item.get("url", "")
                            if not title or not url:
                                continue
                            valid_items.append(item)
                        for item in valid_items:
                            title = item.get("name", "")
                            url = item.get("url", "")
                            image = item.get("cover", "")
                            try:
                                if '\\u' in title:
                                    title = title.encode('utf-8').decode('unicode_escape')
                                elif '&#x' in title:
                                    import html
                                    title = html.unescape(title)
                            except Exception as e:
                                printDBG("Ø®Ø·Ø£ ÙÙŠ ÙÙƒ ØªØ±Ù…ÙŠØ² Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: %s" % str(e))
                            title = re.sub(r'[^\w\s\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF\uFB50-\uFDFF\uFE70-\uFEFF]', '', title)
                            if url and not url.startswith('http'):
                                if url.startswith('/'):
                                    url = self.MAIN_URL + url
                                else:
                                    url = self.MAIN_URL + '/' + url
                            icon = self.getFullUrl(image) if image else self.DEFAULT_ICON_URL
                            ribbon = item.get("ribbon", "")
                            ago = item.get("ago", "")
                            episode = item.get("episode", "")
                            # Ø¨Ù†Ø§Ø¡ Ø§Ù„ÙˆØµÙ
                            desc_parts = []
                            if ribbon: 
                                desc_parts.append('\\c00????00Ø§Ù„Ù†ÙˆØ¹: \\c00????FF' + ribbon)
                            if ago: 
                                desc_parts.append('\\c00????00ÙˆÙ‚Øª Ø§Ù„Ù†Ø´Ø±: \\c00????FF' + ago)
                            if episode: 
                                desc_parts.append('\\c00????00Ø§Ù„Ø­Ù„Ù‚Ø©: \\c00????FF' + str(episode))
                            desc = '\n'.join(desc_parts) if desc_parts else ''
                            if is_episodes:
                                params = {'category': 'video','title': title,'url': url, 'desc': desc,'icon': icon,'good_for_fav': True}
                                self.addVideo(params)
                            else:
                                content_type = self.determineContentType(title, url)
                                if content_type == 'series':
                                    params = {'category': 'list_episodes','title': title,'url': url,'desc': desc,'icon': icon,'good_for_fav': True}
                                    self.addDir(params)
                                else:
                                    params = {'category': 'video','title': title,'desc': desc,'url': url,'icon': icon,'good_for_fav': True}
                                    self.addVideo(params)
                        if len(valid_items) >= 20:
                            last_item = valid_items[-1]
                            new_pick_up_id = str(last_item.get("ID", ""))
                            if new_pick_up_id and new_pick_up_id != pick_up_id:
                                params = dict(cItem)
                                params.update({'title': '\\c00FFFF00ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø²ÙŠØ¯','pick_up_id': new_pick_up_id})
                                self.addDir(params)
                    else:
                        self.addDir({'category': 'list_items', 'title': 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¹Ù†Ø§ØµØ± Ø¥Ø¶Ø§ÙÙŠØ©', 'url': ''})
                except Exception as e:
                    printDBG("Error parsing JSON: %s" % str(e))
                    printDBG("Response content: " + response_text)
                    self.addDir({'category': 'list_items', 'title': 'Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª', 'url': ''})
            else:
                self.addDir({'category': 'list_items', 'title': 'Ø§Ø³ØªØ¬Ø§Ø¨Ø© ÙØ§Ø±ØºØ© Ù…Ù† Ø§Ù„Ø®Ø§Ø¯Ù…', 'url': ''})
        except Exception as e:
            printDBG("Error in load_more: %s" % str(e))
            self.addDir({'category': 'list_items', 'title': 'Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø²ÙŠØ¯', 'url': ''})
    def determineContentType(self, title, url=''):
        title_lower = title.lower()
        url_lower = url.lower() if url else ''
        printDBG(f"=== determineContentType DEBUG ===")
        printDBG(f"Title: {title}")
        printDBG(f"URL: {url}")
        printDBG(f"Title Lower: {title_lower}")
        printDBG(f"URL Lower: {url_lower}")
        episode_keywords = ['Ø­Ù„Ù‚Ø©', 'Ø§Ù„Ø­Ù„Ù‚Ø©', 'episode', 'Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©', 'Ø­Ù„Ù‚Ø© Ø¬Ø¯ÙŠØ¯Ø©',]
        series_keywords = ['Ù…Ø³Ù„Ø³Ù„', 'Ø§Ù„Ù…Ø³Ù„Ø³Ù„', 'series', 'Ù…Ø³Ù„Ø³Ù„Ø§Øª', 'Ø§Ù„Ù…Ø³Ù„Ø³Ù„Ø§Øª','season', 'Ù…ÙˆØ³Ù…', 'Ø§Ù„Ù…ÙˆØ³Ù…', 'Ø³Ù„Ø³Ù„Ø©', 'Ø¨Ø±Ù†Ø§Ù…Ø¬']
        movie_keywords = ['ÙÙŠÙ„Ù…', 'Ø§Ù„ÙÙŠÙ„Ù…', 'movie', 'film', 'Ø£ÙÙ„Ø§Ù…', 'Ø§Ù„Ø£ÙÙ„Ø§Ù…', 'Ø£ØºÙ†ÙŠØ©', 'Ø§ØºÙ†ÙŠØ©', 'Ø£ØºØ§Ù†ÙŠ', 'Ø§ØºØ§Ù†ÙŠ','ÙƒÙ„ÙŠØ¨', 'ÙƒÙ„Ø¨', 'ØªØµÙ…ÙŠÙ…', 'ØªØµØ§Ù…ÙŠÙ…', 'Ù…Ù‚Ø·Ø¹', 'Ù…Ù‚Ø§Ø·Ø¹']
        if any(keyword in url_lower for keyword in ['/Ø§ØºØ§Ù†ÙŠ/', '/Ø£ØºØ§Ù†ÙŠ/', '/music/', '/songs/', '/ØªØµØ§Ù…ÙŠÙ…-', '/design/']):
            result = 'movie'
            printDBG(f"Music/Design section detected: {result}")
            return result
        if any(keyword in title_lower for keyword in ['Ø£ØºÙ†ÙŠØ©', 'Ø§ØºÙ†ÙŠØ©', 'Ø£ØºØ§Ù†ÙŠ', 'Ø§ØºØ§Ù†ÙŠ', 'music', 'ÙƒÙ„ÙŠØ¨', 'ÙƒÙ„Ø¨', 'ØªØµÙ…ÙŠÙ…', 'ØªØµØ§Ù…ÙŠÙ…']):
            result = 'movie'
            printDBG(f"Music/Design title detected: {result}")
            return result
        for keyword in episode_keywords:
            if keyword in title_lower:
                result = 'episode'
                printDBG(f"Episode keyword '{keyword}' detected: {result}")
                return result
        for keyword in series_keywords:
            if keyword in title_lower:
                result = 'series'
                printDBG(f"Series keyword '{keyword}' detected: {result}")
                return result
        for keyword in movie_keywords:
            if keyword in title_lower:
                result = 'movie'
                printDBG(f"Movie keyword '{keyword}' detected: {result}")
                return result
        if re.search(r'(season|Ù…ÙˆØ³Ù…|s)\s*\d+', title_lower):
            result = 'series'
            printDBG(f"Season pattern detected: {result}")
            return result
        if any(keyword in url_lower for keyword in ['/series/', '/Ù…Ø³Ù„Ø³Ù„Ø§Øª/', '/Ù…Ø³Ù„Ø³Ù„/', '/seasons/']):
            result = 'series'
            printDBG(f"Series URL pattern detected: {result}")
            return result
        if any(keyword in url_lower for keyword in ['/movies/', '/Ø£ÙÙ„Ø§Ù…/', '/ÙÙŠÙ„Ù…/', '/film/']):
            result = 'movie'
            printDBG(f"Movie URL pattern detected: {result}")
            return result
        if any(keyword in url_lower for keyword in [
            '/category/Ù…Ø³Ù„Ø³Ù„Ø§Øª-Ø§Ø¬Ù†Ø¨ÙŠØ©',
            '/category/',
            '/series-',
            '/Ù…Ø³Ù„Ø³Ù„-'
        ]) and not any(keyword in url_lower for keyword in ['/Ø§ÙÙ„Ø§Ù…/', '/movies/', '/Ø£ØºØ§Ù†ÙŠ/', '/music/']):
            result = 'series'
            printDBG(f"Foreign series section detected: {result}")
            return result
        if '/Ø£ÙÙ„Ø§Ù…' in url_lower or '/movies' in url_lower:
            result = 'movie'
            printDBG(f"Movies section detected: {result}")
            return result
        result = 'movie'
        printDBG(f"Default result: {result}")
        return result
    def extractDescFromNewly(self, html_block):
        desc_parts = []
        type_match = re.search(r'NewlyRibbon">([^<]+)</div>', html_block)
        if type_match:
            desc_parts.append('\\c00????00Ø§Ù„Ù†ÙˆØ¹: \\c00????FF' + type_match.group(1).strip())
        time_match = re.search(r'NewlyTimeAgo[^>]*>([^<]+)</div>', html_block)
        if time_match:
            desc_parts.append('\\c00????00ÙˆÙ‚Øª Ø§Ù„Ù†Ø´Ø±: \\c00????FF' + time_match.group(1).strip())
        episode_match = re.search(r'NewlyEpNumber[^>]*>.*?(\d+)</div>', html_block)
        if episode_match:
            desc_parts.append('\\c00????00Ø§Ù„Ø­Ù„Ù‚Ø©: \\c00????FF' + episode_match.group(1).strip())
        return '\n'.join(desc_parts) if desc_parts else '\\c00????00Ù…Ø­ØªÙˆÙ‰ Ù…Ø¶Ø§Ù Ø­Ø¯ÙŠØ«Ø§Ù‹'
    def getLinksForVideo(self, cItem):
        printDBG("Lodynet.getLinksForVideo [%s]" % cItem)
        url = cItem.get('url', '')
        sts, data = self.getPage(url)
        if not sts:
            return []
        links = []
        referer = url
        servers = re.findall(r"SwitchServer\(this,\s*'([^']+)'\).*?>([^<]+)<", data)
        if servers:
            for srv_url, srv_name in servers:
                srv_url = self.getFullUrl(srv_url)
                srv_name = srv_name.strip()
                links.append({'name': srv_name,'url': srv_url,'need_resolve': 1,'Referer': referer})
                printDBG(" >> New server: %s (%s)" % (srv_name, srv_url))
        else:
            old_servers = re.findall(r'<li[^>]+data-embed=["\']([^"\']+)["\'][^>]*>([^<]+)<', data)
            for srv_url, srv_name in old_servers:
                srv_url = self.getFullUrl(srv_url)
                srv_name = srv_name.strip()
                links.append({'name': srv_name,'url': srv_url,'need_resolve': 1,'Referer': referer})
                printDBG(" >> Old server: %s (%s)" % (srv_name, srv_url))
        if not links:
            printDBG("Lodynet: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ø±ÙˆØ§Ø¨Ø· Ø³ÙŠØ±ÙØ±.")
            links.append({'name': 'Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ','url': url,'need_resolve': 1,'Referer': referer})
        printDBG("Found %d links" % len(links))
        return links
    def getVideoLinks(self, videoUrl):
        printDBG("Lodynet.getVideoLinks [%s]" % videoUrl)
        if any(x in videoUrl for x in ['vidlo.us', 'viidshar.com', 'govad.xyz', 'vadbam.net']):
            return self.getVidloDirectLinks(videoUrl)
        if videoUrl.endswith('.mp4'):
            return [{'name': 'Direct MP4', 'url': videoUrl}]
        headers = {'User-Agent': self.USER_AGENT, 'Referer': 'https://lodynet.watch/'}
        url_with_meta = strwithmeta(videoUrl, headers)  # ğŸ”¥ Ø§Ø³ØªØ®Ø¯Ø§Ù… videoUrl Ø§Ù„ÙƒØ§Ù…Ù„
        return self.up.getVideoLinkExt(url_with_meta)
    def listSearchResult(self, cItem, searchPattern, searchType):
        printDBG("Lodynet.listSearchResult [%s]" % searchPattern)
        if not searchPattern:
            return
        search_url = self.MAIN_URL + '/wp-content/themes/Lodynet2020/Api/RequestSearch.php?value=' + quote_plus(searchPattern)
        printDBG("Search URL: %s" % search_url)
        headers = {'User-Agent': self.USER_AGENT,'X-Requested-With': 'XMLHttpRequest','Referer': self.MAIN_URL,'Accept': 'application/json, text/javascript, */*; q=0.01'}
        try:
            import requests
            response = requests.get(search_url, headers=headers, timeout=30)
            response_text = response.text
            printDBG("Search API Response: %s" % response_text)
            if response_text and response_text.strip():
                try:
                    data = json.loads(response_text)
                    if isinstance(data, list) and len(data) >= 2:
                        search_results = data[1]
                        if isinstance(search_results, list) and search_results:
                            printDBG("ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ %d Ù†ØªÙŠØ¬Ø© Ø¨Ø­Ø«" % len(search_results))
                            for item in search_results:
                                if not isinstance(item, dict):
                                    continue
                                title = item.get("Title", "")
                                item_url = item.get("Url", "")
                                category = item.get("Category", "")
                                cover = item.get("Cover", "")
                                if not title or not item_url:
                                    continue
                                try:
                                    if '\\u' in title:
                                        title = title.encode('utf-8').decode('unicode_escape')
                                    elif '&#x' in title:
                                        import html
                                        title = html.unescape(title)
                                except:
                                    pass
                                if item_url.startswith('http'):
                                    full_url = item_url
                                else:
                                    try:
                                        decoded_url = urllib.parse.unquote(item_url)
                                        if decoded_url.startswith('/'):
                                            full_url = self.MAIN_URL + decoded_url
                                        else:
                                            full_url = self.MAIN_URL + '/' + decoded_url
                                    except:
                                        full_url = self.MAIN_URL + '/' + item_url
                                icon = self.DEFAULT_ICON_URL
                                if cover:
                                    try:
                                        if '\\/' in cover:
                                            cover = cover.replace('\\/', '/')
                                        icon = self.getFullUrl(cover)
                                    except:
                                        icon = self.DEFAULT_ICON_URL
                                desc_parts = []
                                if category:
                                    desc_parts.append('\\c00????00Ø§Ù„Ù‚Ø³Ù…: \\c00????FF' + category)
                                desc = '\n'.join(desc_parts) if desc_parts else 'Ù†ØªÙŠØ¬Ø© Ø¨Ø­Ø«'
                                content_type = self.determineContentType(title, full_url)
                                if content_type == 'series':
                                    params = {'category': 'list_episodes','title': title.strip(),'url': full_url,'desc': desc,'icon': icon,'good_for_fav': True}
                                    self.addDir(params)
                                else:
                                    params = {'category': 'video','title': title.strip(),'url': full_url,'desc': desc,'icon': icon,'good_for_fav': True}
                                    self.addVideo(params)
                        else:
                            self.addDir({'category': 'search','title': '\\c00FF0000Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬','url': '','desc': 'Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù†ØªØ§Ø¦Ø¬ Ù„Ù„Ø¨Ø­Ø«: ' + searchPattern})
                    else:
                        self.addDir({'category': 'search', 'title': '\\c00FF0000Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª','url': '','desc': 'Ø§Ø³ØªØ¬Ø§Ø¨Ø© ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹Ø© Ù…Ù† Ø®Ø§Ø¯Ù… Ø§Ù„Ø¨Ø­Ø«'})
                except Exception as e:
                    printDBG("Error parsing search JSON: %s" % str(e))
                    printDBG("Raw response: " + response_text)
                    self.addDir({'category': 'search','title': '\\c00FF0000Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬','url': '','desc': 'ØªØ¹Ø°Ø± ØªØ­Ù„ÙŠÙ„ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«: ' + str(e)})
            else:
                self.addDir({'category': 'search','title': '\\c00FF0000Ø§Ø³ØªØ¬Ø§Ø¨Ø© ÙØ§Ø±ØºØ© Ù…Ù† Ø§Ù„Ø®Ø§Ø¯Ù…', 'url': '','desc': 'Ù„Ù… ÙŠØ³ØªØ¬Ø¨ Ø®Ø§Ø¯Ù… Ø§Ù„Ø¨Ø­Ø« Ù„Ù„Ø·Ù„Ø¨'})
        except Exception as e:
            printDBG("Error in search: %s" % str(e))
            self.addDir({'category': 'search','title': '\\c00FF0000Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø«','url': '','desc': 'Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø«: ' + str(e)})
    def getArticleContent(self, cItem):
        printDBG("Lodynet.getArticleContent [%s]" % cItem)
        retTab = []
        url = cItem.get('url', '')
        sts, data = self.getPage(url)
        if not sts:
            return []
        title = cItem.get('title', '')
        icon = cItem.get('icon', self.DEFAULT_ICON_URL)
        desc = cItem.get('desc', '')
        desc_match = re.search(r'<div class="BoxContentInner">(.*?)</div>', data, re.S)
        if desc_match:
            desc = ph.clean_html(desc_match.group(1))
        if title:
            retTab.append({'title': title,'text': desc,'images': [{'title': '', 'url': icon}],'other_info': {}})
        return retTab
    def getVidloDirectLinks(self, baseUrl):
        printDBG('getVidloDirectLinks baseUrl[%s]' % baseUrl)
        COOKIE_FILE = GetCookieDir('vidlo.cookie')
        HTTP_HEADER = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:40.0) Gecko/20100101 Firefox/40.0',
            'Referer': baseUrl
        }
        params = {'header': HTTP_HEADER, 'use_cookie': True, 'save_cookie': True, 'load_cookie': True, 'cookiefile': COOKIE_FILE, 'return_data': True,'follow_redirects': True}
        sts, data = self.cm.getPage(baseUrl, params)
        if not sts:
            printDBG('ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø©')
            return []
        final_url = self.cm.meta.get('url', baseUrl)
        printDBG('Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: %s' % final_url)
        video_urls = []
        if detect(data):
            try:
                unpacked = unpack(data)
                if unpacked:
                    printDBG('ÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ± Ù†Ø¬Ø­ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… jsunpack')
                    data = unpacked + data  # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙÙƒÙˆÙƒØ© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ©
            except Exception as e:
                printDBG('ÙØ´Ù„ ÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… jsunpack: %s' % str(e))
        packed_data = get_packed_data(data)
        if packed_data:
            printDBG('ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¶ØºÙˆØ·Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… get_packed_data')
            data += packed_data
        sources_match = re.search(r'sources\s*:\s*\[([^\]]+)\]', data)
        if sources_match:
            sources_content = sources_match.group(1)
            printDBG('ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ØµØ§Ø¯Ø± Ø§Ù„ÙÙŠØ¯ÙŠÙˆ')
            video_objects = re.findall(r'\{[^{}]*\}', sources_content)
            for obj in video_objects:
                url_match = re.search(r'file["\']?\s*:\s*["\'](https?://[^"\']+)["\']', obj)
                label_match = re.search(r'label["\']?\s*:\s*["\']([^"\']+)["\']', obj)
                if url_match:
                    video_url = url_match.group(1)
                    if label_match:
                        label = label_match.group(1)
                        if '720' in label or 'hd' in label.lower():
                            label = 'HD [720p]'
                        elif '480' in label or 'sd' in label.lower():
                            label = 'SD [480p]'
                        elif '360' in label or 'low' in label.lower():
                            label = 'LOW [360p]'
                    else:
                        if '720p' in video_url.lower() or '/hd/' in video_url.lower():
                            label = 'HD [720p]'
                        elif '1080p' in video_url.lower() or '/fullhd/' in video_url.lower():
                            label = 'FULL HD [1080p]' 
                        elif '480p' in video_url.lower() or '/sd/' in video_url.lower():
                            label = 'SD [480p]'
                        elif '360p' in video_url.lower() or '/low/' in video_url.lower():
                            label = 'LOW [360p]'
                        else:
                            label = 'direct'
                    if video_url not in [v['url'] for v in video_urls]:
                        video_urls.append({'url': video_url, 'label': label})
                        printDBG('ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬: %s [%s]' % (video_url, label))
        if not video_urls:
            printDBG('Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±ÙˆØ§Ø¨Ø· MP4 Ù…Ø¨Ø§Ø´Ø±Ø©')
            quality_patterns = [
                (r'https?://[^\s"\']+?720p[^\s"\']*\.mp4', 'HD [720p]'),
                (r'https?://[^\s"\']+?1080p[^\s"\']*\.mp4', 'FULL HD [1080p]'),
                (r'https?://[^\s"\']+?480p[^\s"\']*\.mp4', 'SD [480p]'),
                (r'https?://[^\s"\']+?360p[^\s"\']*\.mp4', 'LOW [360p]'),
                (r'https?://[^\s"\']+?\.mp4[^\s"\']*', 'direct')
            ]
            for pattern, quality in quality_patterns:
                matches = re.findall(pattern, data)
                for url in matches:
                    if url not in [v['url'] for v in video_urls]:
                        video_urls.append({'url': url, 'label': quality})
                        printDBG('ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ MP4: %s [%s]' % (url, quality))
        vadbam_domains = ['vadbam.net', 'vdbtm.shop']  # ğŸ”¥ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ø·Ø§Ù‚Ø§Øª
        if not video_urls and any(domain in final_url for domain in vadbam_domains):
            printDBG('Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±Ø§Ø¨Ø· vadbam Ø§Ù„Ù…Ø­Ø¯Ø¯')
            token_patterns = [
                r'6jmnwdooziazsalrixwal4fsijsegohjlt2yfv5hhhb2er4ixuc[a-z0-9]+',
                r'[a-z0-9]{50,}'
            ]
            vadbam_token = None
            for pattern in token_patterns:
                token_match = re.search(pattern, data)
                if token_match:
                    vadbam_token = token_match.group(0)
                    printDBG('ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØªÙˆÙƒÙ† vadbam: %s' % vadbam_token)
                    break
            if vadbam_token:
                vadbam_url = 'https://n64no-02.times20qu20.shop/' + vadbam_token + '/v.mp4'
                video_urls.append({'url': vadbam_url, 'label': 'HD [720p]'})
                printDBG('ØªÙ… Ø¨Ù†Ø§Ø¡ Ø±Ø§Ø¨Ø· vadbam: %s' % vadbam_url)
            else:
                vadbam_patterns = [
                    r'https?://n64no-02\.times20qu20\.shop/[^/"\']+?/v\.mp4',
                    r'https?://[a-z0-9\-]+\.times20qu20\.shop/[^/"\']+?/v\.mp4'
                ]
                for pattern in vadbam_patterns:
                    vadbam_match = re.search(pattern, data)
                    if vadbam_match:
                        video_urls.append({'url': vadbam_match.group(0), 'label': 'HD [720p]'})
                        printDBG('ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· vadbam Ù…Ø¨Ø§Ø´Ø±Ø©: %s' % vadbam_match.group(0))
                        break
        govad_domains = ['govad.xyz', 'goveed1.space']
        if not video_urls and any(domain in final_url for domain in govad_domains):
            printDBG('Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±Ø§Ø¨Ø· govad Ø§Ù„Ù…Ø­Ø¯Ø¯')
            token_patterns = [
                r'to3qvsqfkjvsy46b3v6wxj5miprsdgtglca2uskke2wsfieaih2[a-z0-9]+',
                r'[a-z0-9]{50,}'
            ]
            govad_token = None
            for pattern in token_patterns:
                token_match = re.search(pattern, data)
                if token_match:
                    govad_token = token_match.group(0)
                    printDBG('ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØªÙˆÙƒÙ† govad: %s' % govad_token)
                    break
            if govad_token:
                govad_url = 'https://wsxcvx6.zfghrew10.shop/' + govad_token + '/v.mp4'
                video_urls.append({'url': govad_url, 'label': 'HD [720p]'})
                printDBG('ØªÙ… Ø¨Ù†Ø§Ø¡ Ø±Ø§Ø¨Ø· govad: %s' % govad_url)
            else:
                govad_patterns = [
                    r'https?://wsxcvx6\.zfghrew10\.shop/[^/"\']+?/v\.mp4',
                    r'https?://[a-z0-9\-]+\.zfghrew10\.shop/[^/"\']+?/v\.mp4'
                ]
                for pattern in govad_patterns:
                    govad_match = re.search(pattern, data)
                    if govad_match:
                        video_urls.append({'url': govad_match.group(0), 'label': 'HD [720p]'})
                        printDBG('ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· govad Ù…Ø¨Ø§Ø´Ø±Ø©: %s' % govad_match.group(0))
                        break
        if not video_urls and 'vidlo.us' in final_url:
            printDBG('Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±ÙˆØ§Ø¨Ø· vidlo Ù…Ø¹ Ø§Ù„Ø¬ÙˆØ¯Ø§Øª')
            vidlo_patterns = [
                r'https?://[a-z0-9]+\.vidlo\.us/[a-z0-9]+/v\.mp4',
                r'https?://vidlo\.us/[a-z0-9]+/v\.mp4'
            ]
            vidlo_links_found = []
            for pattern in vidlo_patterns:
                matches = re.findall(pattern, data)
                for url in matches:
                    if url not in vidlo_links_found:
                        vidlo_links_found.append(url)
            if vidlo_links_found:
                vidlo_links_found.sort(key=len)
                quality_labels = ['HD [720p]', 'SD [480p]', 'LOW [360p]']
                for i, url in enumerate(vidlo_links_found):
                    if i < len(quality_labels):
                        label = quality_labels[i]
                    else:
                        label = f'Quality {i+1}'
                    if url not in [v['url'] for v in video_urls]:
                        video_urls.append({'url': url, 'label': label})
                        printDBG('ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· vidlo: %s [%s]' % (url, label))
        if not video_urls:
            printDBG('Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±ÙˆØ§Ø¨Ø· Ù…Ø¨Ø§Ø´Ø±Ø© ÙÙŠ HTML')
            direct_patterns = [
                r'src\s*=\s*["\'](https?://[^"\']+?\.mp4[^"\']*)["\']',
                r'file["\']?\s*=\s*["\'](https?://[^"\']+?\.mp4[^"\']*)["\']',
                r'(https?://[^\s"\'<>]+\.mp4[^"\'<>]*)'
            ]
            direct_links_found = []
            for pattern in direct_patterns:
                matches = re.findall(pattern, data)
                for match in matches:
                    if (match.startswith('http') and 
                        'adblocktape.wiki' not in match and 
                        match not in direct_links_found):
                        direct_links_found.append(match)
            if direct_links_found:
                quality_order = ['720p', '1080p', '480p', '360p', 'hd', 'sd', 'low']
                direct_links_found.sort(key=lambda x: any(q in x.lower() for q in quality_order), reverse=True)
                for i, url in enumerate(direct_links_found):
                    if '720p' in url.lower() or 'hd' in url.lower():
                        label = 'HD [720p]'
                    elif '480p' in url.lower() or 'sd' in url.lower():
                        label = 'SD [480p]'
                    elif '360p' in url.lower() or 'low' in url.lower():
                        label = 'LOW [360p]'
                    elif '1080p' in url.lower() or 'fullhd' in url.lower():
                        label = 'FULL HD [1080p]'
                    else:
                        if i == 0:
                            label = 'HD [720p]'
                        elif i == 1:
                            label = 'SD [480p]'
                        elif i == 2:
                            label = 'LOW [360p]'
                        else:
                            label = f'Quality {i+1}'
                    if url not in [v['url'] for v in video_urls]:
                        video_urls.append({'url': url, 'label': label})
                        printDBG('ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· ÙÙŠ HTML: %s [%s]' % (url, label))
        if video_urls:
            quality_priority = {'FULL HD [1080p]': 0,'HD [720p]': 1, 'SD [480p]': 2,'LOW [360p]': 3}
            def get_quality_priority(item):
                label = item['label']
                return quality_priority.get(label, 999)
            video_urls.sort(key=get_quality_priority)
            result = []
            for item in video_urls:
                result.append({
                    'name': item['label'],
                    'url': strwithmeta(item['url'], {
                        'Referer': final_url,
                        'User-Agent': HTTP_HEADER['User-Agent']
                    })
                })
            printDBG('ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ %d Ø±Ø§Ø¨Ø·' % len(result))
            for item in result:
                printDBG('   - %s: %s' % (item['name'], item['url']))
            return result
        printDBG('Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ø±Ø§Ø¨Ø· ÙÙŠØ¯ÙŠÙˆ')
        return []
    def handleService(self, index, refresh=0, searchPattern='', searchType=''):
        printDBG('Lodynet.handleService start')
        CBaseHostClass.handleService(self, index, refresh, searchPattern, searchType)
        name = self.currItem.get("name", '')
        category = self.currItem.get("category", '')
        printDBG("handleService: || name[%s], category[%s]" % (name, category))
        self.currList = []
        if name is None:
            self.listMainMenu({'name': 'category'})
        elif category == 'sub_menu':
            self.listSubMenu(self.currItem)
        elif category == 'list_items':
            self.listItems(self.currItem)
        elif category == 'list_episodes':
            self.listEpisodes(self.currItem)
        elif category == 'load_more':
            self.loadMore(self.currItem)
        elif category == 'load_more_episodes':
            self.loadMore(self.currItem)
        elif category == 'search':
            self.listSearchResult(self.currItem, searchPattern, searchType)
        elif category == 'search_history':
            self.listsHistory({'category': 'search', 'name': 'history'})
        elif category == 'delete_history':
            self.delHistory(self.sessionEx)
    def listsHistory(self, baseItem={'name': 'history', 'category': 'search'}, desc_key='plot', desc_base=("Ø§Ù„Ù†ÙˆØ¹: ")):
        list = self.history.getHistoryList()
        for histItem in list:
            plot = ''
            try:
                if type(histItem) is type({}):
                    pattern = histItem.get('pattern', '')
                    search_type = histItem.get('type', '')
                    if '' != search_type:
                        plot = desc_base + search_type
                else:
                    pattern = histItem
                    search_type = None
                params = dict(baseItem)
                params.update({'title': pattern, 'search_type': search_type, desc_key: plot})
                self.addDir(params)
            except Exception:
                printExc()
    def start(self, cItem):
        return self.handleService(cItem)
class IPTVHost(CHostBase):
    def __init__(self):
        CHostBase.__init__(self, Lodynet(), True, [])
    def withArticleContent(self, cItem):
        if 'video' == cItem.get('type', '') or 'list_episodes' == cItem.get('category', ''):
            return True
        return False
###################################################################### Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡